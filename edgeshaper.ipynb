{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import torch, os, random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from modules.dualgraph.mol import smiles2graphwithface\n",
    "from modules.dualgraph.gnn import GNN\n",
    "from modules.dualgraph.dataset import DGData\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import dgl\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from EdgeShaper.edgeshaper import batch_edgeshaper\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit import Chem, Geometry\n",
    "from rdkit.Chem import AllChem, Draw, rdMolAlign, rdDepictor\n",
    "\n",
    "from IPython.display import SVG\n",
    "import seaborn as sns\n",
    "from modules.equevlalent import get_equivalent_bonds\n",
    "from copy import deepcopy\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(InMemoryDataset):\n",
    "    def __init__(self, root='dataset_path', transform=None, pre_transform=None, df=None, target_type='MLM', mode='train'):\n",
    "        self.df = df\n",
    "        self.target_type = target_type\n",
    "        self.mode = mode\n",
    "        super().__init__(root, transform, pre_transform, df)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):        \n",
    "        return [f'raw_{i+1}.pt' for i in range(self.df.shape[0])]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'data_{i+1}.pt' for i in range(self.df.shape[0])]        \n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def get(self, idx):        \n",
    "        return self.graph_list[idx]\n",
    "\n",
    "    def process(self):        \n",
    "        smiles_list = self.df[\"SMILES\"].values\n",
    "        targets_list = self.df[['MLM', 'HLM']].values\n",
    "        test_id_list = self.df['id'].values\n",
    "        data_list = []\n",
    "        for i in range(len(smiles_list)):\n",
    "            data = DGData()\n",
    "            smiles = smiles_list[i]\n",
    "            targets = targets_list[i]\n",
    "            graph = smiles2graphwithface(smiles)\n",
    "\n",
    "            data.__num_nodes__ = int(graph[\"num_nodes\"])\n",
    "            data.edge_index = torch.from_numpy(graph[\"edge_index\"]).to(torch.int64)\n",
    "            data.edge_attr = torch.from_numpy(graph[\"edge_feat\"]).to(torch.int64)\n",
    "            data.x = torch.from_numpy(graph[\"node_feat\"]).to(torch.int64)\n",
    "            data.y = torch.Tensor([targets])\n",
    "\n",
    "            data.ring_mask = torch.from_numpy(graph[\"ring_mask\"]).to(torch.bool)\n",
    "            data.ring_index = torch.from_numpy(graph[\"ring_index\"]).to(torch.int64)\n",
    "            data.nf_node = torch.from_numpy(graph[\"nf_node\"]).to(torch.int64)\n",
    "            data.nf_ring = torch.from_numpy(graph[\"nf_ring\"]).to(torch.int64)\n",
    "            data.num_rings = int(graph[\"num_rings\"])\n",
    "            data.n_edges = int(graph[\"n_edges\"])\n",
    "            data.n_nodes = int(graph[\"n_nodes\"])\n",
    "            data.n_nfs = int(graph[\"n_nfs\"])        \n",
    "            data.smile = smiles\n",
    "            data.id = test_id_list[i]\n",
    "            \n",
    "\n",
    "            data_list.append(data)\n",
    "        self.smiles_list = smiles_list  \n",
    "        self.graph_list = data_list\n",
    "        self.targets_list = targets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_paper.csv')\n",
    "test_df['MLM_raw'], test_df['HLM_raw'] = test_df['MLM_raw'].str.replace('<', '').str.replace('>', ''), test_df['HLM_raw'].str.replace('<', '').str.replace('>', '')\n",
    "test_df['MLM'], test_df['HLM'] = test_df['MLM_raw'].astype(float), test_df['HLM_raw'].astype(float)\n",
    "test_df.loc[test_df['HLM'] > 100, 'HLM'] = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 14) (195, 14)\n"
     ]
    }
   ],
   "source": [
    "stable_df = test_df[test_df['HLM'] >= 50].reset_index(drop=True)\n",
    "unstable_df = test_df[test_df['HLM'] < 50].reset_index(drop=True)\n",
    "\n",
    "print(stable_df.shape, unstable_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "stable_dataset = CustomDataset(df = stable_df, mode='test', target_type='MLM')\n",
    "stable_loader = DataLoader(stable_dataset, batch_size=1, shuffle=False, num_workers = 8) \n",
    "\n",
    "unstable_dataset = CustomDataset(df = unstable_df, mode='test', target_type='MLM')\n",
    "unstable_loader = DataLoader(unstable_dataset, batch_size=1, shuffle=False, num_workers = 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaboGNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, mode):\n",
    "        super(MetaboGNN, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.ddi = True\n",
    "        self.gnn = GNN(mlp_hidden_size = 512, mlp_layers = 2, latent_size = 128, use_layer_norm = False,\n",
    "                        use_face=True, ddi=self.ddi, dropedge_rate = 0.1, dropnode_rate = 0.1, dropout = 0.1,\n",
    "                        dropnet = 0.1, global_reducer = \"sum\", node_reducer = \"sum\", face_reducer = \"sum\", graph_pooling = \"sum\",                        \n",
    "                        node_attn = True, face_attn = True)\n",
    "        if self.mode != 'Scratch':\n",
    "            state_dict=  torch.load('GraphCL/gnn_pretrain.pt', map_location='cpu')\n",
    "            self.gnn.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.LayerNorm(128),\n",
    "                    nn.Linear(128, 128,),\n",
    "                    nn.BatchNorm1d(128),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 1),\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.LayerNorm(128),\n",
    "                    nn.Linear(128, 128,),\n",
    "                    nn.BatchNorm1d(128),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 1),\n",
    "                    )\n",
    "\n",
    "        self.fc1[-1].weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.fc2[-1].weight.data.normal_(mean=0.0, std=0.01)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        mol = self.gnn(batch)\n",
    "\n",
    "        out1 = torch.sigmoid(self.fc1(mol).squeeze(1)) * 100        \n",
    "        if self.mode == 'MetaboGNN':\n",
    "            out2 = (torch.sigmoid(self.fc2(mol).squeeze(1))-0.5) * 200\n",
    "        else:\n",
    "            out2 = torch.sigmoid(self.fc1(mol).squeeze(1)) * 100        \n",
    "\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaboGNN(\n",
       "  (gnn): GNN(\n",
       "    (encoder_edge): MLPwoLastAct(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Linear(in_features=13, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_node): MLPwoLastAct(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Linear(in_features=174, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_face): MLPwoLastAct(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gnn_layers): ModuleList(\n",
       "      (0-6): 7 x MetaLayer2(\n",
       "        (edge_model): DropoutIfTraining(\n",
       "          (submodule): MLP(\n",
       "            (module_list): ModuleList(\n",
       "              (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): ReLU()\n",
       "              (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (5): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (node_model): DropoutIfTraining(\n",
       "          (submodule): MLP(\n",
       "            (module_list): ModuleList(\n",
       "              (0): Linear(in_features=640, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): ReLU()\n",
       "              (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (5): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (face_model): MLP(\n",
       "          (module_list): ModuleList(\n",
       "            (0): Linear(in_features=640, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): ReLU()\n",
       "            (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (5): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (global_model): MLP(\n",
       "          (module_list): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): ReLU()\n",
       "            (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (5): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (node_attn): NodeAttn(\n",
       "          (w1): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (w3): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (face_node_attn): GlobalAttn(\n",
       "          (w1): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (face_edge_attn): GlobalAttn(\n",
       "          (w1): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): MetaLayer2(\n",
       "        (edge_model): DropoutIfTraining(\n",
       "          (submodule): MLP(\n",
       "            (module_list): ModuleList(\n",
       "              (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): ReLU()\n",
       "              (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (5): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (node_model): DropoutIfTraining(\n",
       "          (submodule): MLP(\n",
       "            (module_list): ModuleList(\n",
       "              (0): Linear(in_features=640, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (3): ReLU()\n",
       "              (4): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (5): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (node_attn): NodeAttn(\n",
       "          (w1): Linear(in_features=384, out_features=128, bias=True)\n",
       "          (w3): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MLPwoLastAct(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MetaboGNN(mode = 'MetaboGNN').to(device)\n",
    "model.load_state_dict(torch.load('ckpt/2025_MetaboGNN.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def extract_bond_fragments(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    fragments = []\n",
    "\n",
    "    for bond in mol.GetBonds():\n",
    "        # Determine bond type representation\n",
    "        bond_type = \":\" if bond.GetIsAromatic() else (\n",
    "            \"=\" if bond.GetBondTypeAsDouble() == 2.0 else (\n",
    "                \"-\" if bond.GetBondTypeAsDouble() == 1.0 else \"#\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        end_atom = bond.GetEndAtom()\n",
    "\n",
    "        begin_atom_symbol = begin_atom.GetSymbol().lower() if begin_atom.GetIsAromatic() else begin_atom.GetSymbol().upper()\n",
    "        end_atom_symbol = end_atom.GetSymbol().lower() if end_atom.GetIsAromatic() else end_atom.GetSymbol().upper()\n",
    "\n",
    "        bond_representation = f\"{begin_atom_symbol}{bond_type}{end_atom_symbol}\"\n",
    "\n",
    "        neighbors_repr = []\n",
    "\n",
    "        for atom in [begin_atom, end_atom]:\n",
    "            atom_neighbors = []\n",
    "            for neighbor in atom.GetNeighbors():\n",
    "                if neighbor.GetIdx() != begin_atom.GetIdx() and neighbor.GetIdx() != end_atom.GetIdx():\n",
    "                    neighbor_bond = mol.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
    "                    neighbor_bond_type = \":\" if neighbor_bond.GetIsAromatic() else (\n",
    "                        \"=\" if neighbor_bond.GetBondTypeAsDouble() == 2.0 else (\n",
    "                            \"-\" if neighbor_bond.GetBondTypeAsDouble() == 1.0 else \"#\"\n",
    "                        )\n",
    "                    )\n",
    "                    neighbor_symbol = neighbor.GetSymbol().lower() if neighbor.GetIsAromatic() else neighbor.GetSymbol().upper()\n",
    "                    atom_neighbors.append(\n",
    "                        f\"{atom.GetSymbol().lower() if atom.GetIsAromatic() else atom.GetSymbol().upper()}{neighbor_bond_type}{neighbor_symbol}\"\n",
    "                    )\n",
    "            if atom_neighbors:\n",
    "                neighbors_repr.append(\",\".join(atom_neighbors))\n",
    "\n",
    "        fragment_str = f\"{bond_representation}\\n{';'.join(neighbors_repr)}\"\n",
    "        fragments.append(fragment_str)\n",
    "\n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeShaperDataset(InMemoryDataset):\n",
    "    def __init__(self, root='dataset_path', transform=None, pre_transform=None, df=None, target_type='MLM', mode='train', symmetric_pairs=None):        \n",
    "        self.df = df\n",
    "        self.target_type = target_type\n",
    "        self.mode = mode\n",
    "        self.symmetric_pairs = symmetric_pairs\n",
    "        super().__init__(root, transform, pre_transform, df)\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):        \n",
    "        return [f'raw_{i+1}.pt' for i in range(self.df.shape[0])]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'data_{i+1}.pt' for i in range(self.df.shape[0])]        \n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graph_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        graph = self.graph_list[idx]\n",
    "        j= self.df.loc[idx, 'j']        \n",
    "\n",
    "        num_nodes = graph['n_nodes']\n",
    "        num_edges = graph['n_edges']\n",
    "\n",
    "        max_num_edges = num_nodes*(num_nodes-1)\n",
    "        graph_density = num_edges/max_num_edges\n",
    "        # P = graph_density\n",
    "        P = 0.7\n",
    "\n",
    "        E_z_mask = rng.binomial(1, P, num_edges)\n",
    "        E_mask = torch.ones(num_edges)\n",
    "        pi = torch.randperm(num_edges)\n",
    "\n",
    "        E_j_plus_index = torch.ones(num_edges, dtype=torch.int)\n",
    "        E_j_minus_index = torch.ones(num_edges, dtype=torch.int)\n",
    "        selected_edge_index = np.where(pi == j)[0].item()\n",
    "\n",
    "        # dictionary로 변환하여 쉽게 참조\n",
    "        symmetric_dict = {}\n",
    "        for pair in self.symmetric_pairs:\n",
    "            symmetric_dict[pair[0]] = pair[1]\n",
    "            symmetric_dict[pair[1]] = pair[0]\n",
    "\n",
    "        E_j_plus_index = torch.ones(num_edges, dtype=torch.int)\n",
    "        E_j_minus_index = torch.ones(num_edges, dtype=torch.int)\n",
    "        selected_edge_index = np.where(pi == j)[0].item()\n",
    "\n",
    "        # E_j_plus_index 처리\n",
    "        for k in range(num_edges):\n",
    "            current_edge = pi[k].item()\n",
    "            if k <= selected_edge_index:\n",
    "                mask_value = E_mask[current_edge]\n",
    "            else:\n",
    "                mask_value = E_z_mask[current_edge]\n",
    "            \n",
    "            E_j_plus_index[current_edge] = mask_value\n",
    "            # symmetric한 edge가 있다면 같은 mask 적용\n",
    "            if current_edge in symmetric_dict:\n",
    "                E_j_plus_index[symmetric_dict[current_edge]] = mask_value\n",
    "\n",
    "        # E_j_minus_index 처리\n",
    "        for k in range(num_edges):\n",
    "            current_edge = pi[k].item()\n",
    "            if k < selected_edge_index:\n",
    "                mask_value = E_mask[current_edge]\n",
    "            else:\n",
    "                mask_value = E_z_mask[current_edge]\n",
    "            \n",
    "            E_j_minus_index[current_edge] = mask_value\n",
    "            # symmetric한 edge가 있다면 같은 mask 적용\n",
    "            if current_edge in symmetric_dict:\n",
    "                E_j_minus_index[symmetric_dict[current_edge]] = mask_value\n",
    "\n",
    "        retained_indices_plus = torch.LongTensor(torch.nonzero(E_j_plus_index).tolist()).squeeze()\n",
    "        retained_indices_minus = torch.LongTensor(torch.nonzero(E_j_minus_index).tolist()).squeeze()\n",
    "\n",
    "        if len(retained_indices_plus.shape) == 0:\n",
    "            retained_indices_plus = retained_indices_plus.unsqueeze(0)\n",
    "        if len(retained_indices_minus.shape) == 0:\n",
    "            retained_indices_minus = retained_indices_minus.unsqueeze(0)    \n",
    "\n",
    "        plus_graph = graph.clone()\n",
    "        minus_graph = graph.clone()\n",
    "\n",
    "        plus_graph.ring_index = graph.ring_index[:, retained_indices_plus]\n",
    "        minus_graph.ring_index = graph.ring_index[:, retained_indices_minus]\n",
    "\n",
    "        plus_graph.edge_attr = graph.edge_attr[retained_indices_plus]\n",
    "        minus_graph.edge_attr = graph.edge_attr[retained_indices_minus]\n",
    "\n",
    "        plus_graph.edge_index = graph.edge_index[:, retained_indices_plus]\n",
    "        minus_graph.edge_index = graph.edge_index[:, retained_indices_minus]\n",
    "\n",
    "        plus_graph.num_edges = retained_indices_plus.shape[0]\n",
    "        minus_graph.num_edges = retained_indices_minus.shape[0]\n",
    "\n",
    "        plus_graph.n_edges = retained_indices_plus.shape[0]\n",
    "        minus_graph.n_edges = retained_indices_minus.shape[0]\n",
    "\n",
    "        return plus_graph, minus_graph\n",
    "\n",
    "    def process(self):\n",
    "        smiles_list = self.df[\"SMILES\"].values\n",
    "        targets_list = self.df[['MLM', 'HLM']].values\n",
    "        test_id_list = self.df['id'].values\n",
    "        self.mol_list = []\n",
    "        data_list = []\n",
    "        for i in range(len(smiles_list)):\n",
    "            data = DGData()\n",
    "            smiles = smiles_list[i]\n",
    "            self.mol_list.append(Chem.MolFromSmiles(smiles))\n",
    "            targets = targets_list[i]\n",
    "            graph = smiles2graphwithface(smiles)\n",
    "\n",
    "            data.__num_nodes__ = int(graph[\"num_nodes\"])\n",
    "            data.edge_index = torch.from_numpy(graph[\"edge_index\"]).to(torch.int64)\n",
    "            data.edge_attr = torch.from_numpy(graph[\"edge_feat\"]).to(torch.int64)\n",
    "            data.x = torch.from_numpy(graph[\"node_feat\"]).to(torch.int64)\n",
    "            data.y = torch.Tensor([targets])\n",
    "\n",
    "            data.ring_mask = torch.from_numpy(graph[\"ring_mask\"]).to(torch.bool)\n",
    "            data.ring_index = torch.from_numpy(graph[\"ring_index\"]).to(torch.int64)\n",
    "            data.nf_node = torch.from_numpy(graph[\"nf_node\"]).to(torch.int64)\n",
    "            data.nf_ring = torch.from_numpy(graph[\"nf_ring\"]).to(torch.int64)\n",
    "            data.num_rings = int(graph[\"num_rings\"])\n",
    "            data.n_edges = int(graph[\"n_edges\"])\n",
    "            data.n_nodes = int(graph[\"n_nodes\"])\n",
    "            data.n_nfs = int(graph[\"n_nfs\"])        \n",
    "            data.smile = smiles\n",
    "            data.id = test_id_list[i]\n",
    "\n",
    "            data_list.append(data)\n",
    "        self.smiles_list = smiles_list  \n",
    "        self.graph_list = data_list\n",
    "        self.targets_list = targets_list\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_shape_df(test_df, num_edges, M):\n",
    "    edge_shape_df =[]\n",
    "    for j in range(num_edges):\n",
    "        dd = test_df.loc[[i]].sample(M , replace=True)\n",
    "        dd['j'] = j\n",
    "        edge_shape_df.append(dd)\n",
    "    edge_shape_df = pd.concat(edge_shape_df).reset_index(drop=True)\n",
    "    return edge_shape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('EdgeShaper/scores',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "fragments_df = []\n",
    "\n",
    "for i in tqdm(range(test_df.shape[0])):\n",
    "    smile = test_df.loc[i, 'SMILES']\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    _, symmetric_pairs = get_equivalent_bonds(mol)\n",
    "    graph = smiles2graphwithface(smile)\n",
    "    num_edges = graph['edge_feat'].shape[0]\n",
    "\n",
    "    edge_shape_df = get_edge_shape_df(test_df, num_edges, M)\n",
    "    \n",
    "    edgeshaper_dataset = EdgeShaperDataset(df = edge_shape_df, mode='test', target_type='HLM', symmetric_pairs=symmetric_pairs)\n",
    "    edgeshaper_loader = DataLoader(edgeshaper_dataset, batch_size=M, shuffle=False, num_workers = 8) \n",
    "\n",
    "    stable_edges_explanations = []\n",
    "\n",
    "    for plus_batch, minus_batch in edgeshaper_loader:                        \n",
    "        with torch.no_grad():\n",
    "            plus_mlm, plus_res = model(plus_batch.to(device))\n",
    "            plus_hlm = plus_mlm - plus_res\n",
    "\n",
    "            minus_mlm, minus_res = model(minus_batch.to(device))\n",
    "            minus_hlm = minus_mlm - minus_res    \n",
    "        \n",
    "        plus_stable, minus_stable = (plus_hlm-50).abs(), (minus_hlm-50).abs()         \n",
    "        stability_impact = plus_stable - minus_stable\n",
    "                \n",
    "        avg_stability_impact = stability_impact.mean()        \n",
    "        stability_weighted_contrib = avg_stability_impact.item() #* np.sign(marginal_contrib)        \n",
    "        stable_edges_explanations.append(stability_weighted_contrib)        \n",
    "\n",
    "        \n",
    "    stable_edges_explanations = np.array(stable_edges_explanations)\n",
    "\n",
    "    plus_res\n",
    "    test_id = test_df.loc[i, 'id']\n",
    "\n",
    "    fragments = extract_bond_fragments(smile)\n",
    "\n",
    "    for n, fragment in  enumerate(fragments):\n",
    "        stable_score = stable_edges_explanations[n*2] +  stable_edges_explanations[n*2+1]    \n",
    "        fragments_df.append({'fragment' : fragment, 'stable_score' : stable_score, 'mol_idx' : i})\n",
    "    \n",
    "    np.save(f'EdgeShaper/scores/{test_id}.npy', stable_edges_explanations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments_df = pd.DataFrame(fragments_df)\n",
    "fragments_df.to_csv('fragments_df.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment</th>\n",
       "      <th>stable_score</th>\n",
       "      <th>mol_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-C\\nC-C,C-N</td>\n",
       "      <td>0.202087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-C\\nC-C,C-N</td>\n",
       "      <td>-0.019427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-N\\nC-C,C-C;N-c</td>\n",
       "      <td>-0.455400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N-c\\nN-C;c:c,c:n</td>\n",
       "      <td>0.091446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:c\\nc-N,c:n;c:c</td>\n",
       "      <td>-0.557052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fragment  stable_score  mol_idx\n",
       "0      C-C\\nC-C,C-N      0.202087        0\n",
       "1      C-C\\nC-C,C-N     -0.019427        0\n",
       "2  C-N\\nC-C,C-C;N-c     -0.455400        0\n",
       "3  N-c\\nN-C;c:c,c:n      0.091446        0\n",
       "4  c:c\\nc-N,c:n;c:c     -0.557052        0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
